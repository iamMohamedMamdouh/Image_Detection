import streamlit as st
from PIL import Image
from ultralytics import YOLO
import numpy as np
from gtts import gTTS
import pygame
import tempfile
import os
from collections import Counter

st.set_page_config(page_title="Image Detection Model", layout="centered")
st.title("Image Detection Model")
st.markdown("Upload an image and see the result after the model analyzes it")

model = YOLO("yolov8n.pt")

translate = {
    "person": "Ø´Ø®Øµ",
    "car": "Ø³ÙŠØ§Ø±Ø©",
    "truck": "Ø´Ø§Ø­Ù†Ø©",
    "bus": "Ø£ØªÙˆØ¨ÙŠØ³",
    "bicycle": "Ø¯Ø±Ø§Ø¬Ø©",
    "motorcycle": "Ø¯Ø±Ø§Ø¬Ø© Ù†Ø§Ø±ÙŠØ©",
    "cat": "Ù‚Ø·Ø©",
    "dog": "ÙƒÙ„Ø¨",
    "traffic light": "Ø¥Ø´Ø§Ø±Ø© Ù…Ø±ÙˆØ±",
    "handbag": "Ø­Ù‚ÙŠØ¨Ø© ÙŠØ¯",
    "chair": "ÙƒØ±Ø³ÙŠ",
    "bird": "Ø·Ø§Ø¦Ø±",
    "boat": "Ù‚Ø§Ø±Ø¨",
    "backpack": "Ø­Ù‚ÙŠØ¨Ø© Ø¸Ù‡Ø±",
}

uploaded_file = st.file_uploader("Upload a picture", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    img_array = np.array(image)

    st.subheader("The picture:")
    st.image(image, use_container_width=True)

    result = model.predict(img_array, conf=0.3)[0]
    boxes = result.boxes.data
    class_names = result.names

    st.subheader("The image after Detection:")
    st.image(result.plot(), caption="âœ… Detected Image", use_container_width=True)


    detected_labels = [class_names[int(cls)] for *_, cls in boxes.tolist()]
    if detected_labels:
        counts = Counter(detected_labels)

        col1, col2 = st.columns([1, 3])
        with col1:
            lang_choice = st.selectbox("ğŸŒ", ["English", "Ø¹Ø±Ø¨ÙŠ"], index=0, label_visibility="collapsed")
        with col2:
            speak = st.button("ğŸ”Š Announcing the results")

        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†Øµ
        lines = []
        if lang_choice == "Ø¹Ø±Ø¨ÙŠ":
            for k, v in counts.items():
                arabic = translate.get(k, k)
                if v == 1:
                    lines.append(f"{arabic} ÙˆØ§Ø­Ø¯")
                else:
                    lines.append(f"{v} {arabic}")
            speak_text = "ØªÙ… Ø§ÙƒØªØ´Ø§Ù: " + "ØŒ ".join(lines)
        else:
            for k, v in counts.items():
                label = k if v == 1 else f"{v} {k}s"
                lines.append(label)
            speak_text = "Detected: " + ", ".join(lines)

        display_text = "\n".join([f"- {line}" for line in lines])
        st.success("ğŸ“Š Results:\n" + display_text)

        if speak:
            try:
                tts = gTTS(text=speak_text, lang='ar' if lang_choice == "Ø¹Ø±Ø¨ÙŠ" else 'en')
                tmp_path = os.path.join(tempfile.gettempdir(), "speech.mp3")
                tts.save(tmp_path)

                pygame.mixer.init()
                pygame.mixer.music.load(tmp_path)
                pygame.mixer.music.play()
                while pygame.mixer.music.get_busy():
                    pygame.time.Clock().tick(10)

                pygame.mixer.quit()
                os.remove(tmp_path)
            except Exception as e:
                st.error(f"âš  Ø­ØµÙ„Øª Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ù†Ø·Ù‚: {str(e)}")
    else:
        st.warning("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙƒØ§Ø¦Ù†Ø§Øª ØªÙ… Ø§ÙƒØªØ´Ø§ÙÙ‡Ø§.")
#///////////////////////HTML///////////////////////////
# import streamlit as st
# from PIL import Image
# from ultralytics import YOLO
# import numpy as np
# import cv2
# import base64
# import streamlit.components.v1 as components
#
# st.set_page_config(page_title="ğŸ§  YOLO Interactive Voice", layout="centered")
# st.title("ğŸ§  YOLO Interactive Detection with Voice")
#
# model = YOLO("yolov8n.pt")  # Ø£Ùˆ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù„ÙŠ Ø¯Ø±Ø¨ØªÙ‡
#
# uploaded_file = st.file_uploader("ğŸ“¸ Ø§Ø±ÙØ¹ ØµÙˆØ±Ø©", type=["jpg", "jpeg", "png"])
#
# if uploaded_file:
#     image = Image.open(uploaded_file).convert("RGB")
#     img_array = np.array(image)
#     w, h = image.size
#
#     st.subheader("ğŸ“· Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©:")
#     st.image(image, caption="Original Image", use_column_width=False)
#
#     # ğŸ” YOLO Prediction
#     results = model.predict(img_array, conf=0.3)[0]
#
#     # ğŸ¨ Ø±Ø³Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬
#     annotated_img = results.plot()
#     _, buffer = cv2.imencode(".jpg", annotated_img)
#     img_base64 = base64.b64encode(buffer).decode()
#
#     st.subheader("ğŸ§  Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
#
#     # ğŸ“¦ Ø¨Ù†Ø§Ø¡ HTML ØªÙØ§Ø¹Ù„ÙŠ
#     html = f"""
#     <html>
#     <head>
#     <style>
#         .container {{
#             position: relative;
#             width: {w}px;
#             height: {h}px;
#             background-image: url("data:image/jpg;base64,{img_base64}");
#             background-size: contain;
#             background-repeat: no-repeat;
#             background-position: top left;
#             border: 2px solid #999;
#         }}
#         .box {{
#             position: absolute;
#             border: 2px solid red;
#             cursor: pointer;
#             z-index: 10;
#         }}
#     </style>
#     </head>
#     <body>
#     <div class="container">
#     """
#
#     # ğŸ§  Ø¥Ø¶Ø§ÙØ© Ø¨ÙˆÙƒØ³Ø§Øª Ùˆ onclick Ù†Ø§Ø·Ù‚
#     for box in results.boxes.data:
#         x1, y1, x2, y2, conf, cls = box.tolist()
#         label = results.names[int(cls)]
#         box_width = x2 - x1
#         box_height = y2 - y1
#
#         html += f"""
#         <div class="box" onclick="speak('{label}')"
#             style="left:{x1}px; top:{y1}px; width:{box_width}px; height:{box_height}px;"
#             title="{label}">
#         </div>
#         """
#
#     # ğŸ”Š JavaScript Ù†Ø·Ù‚ Ø¹Ù†Ø¯ Ø§Ù„Ø¶ØºØ·
#     html += """
#     </div>
#     <script>
#     function speak(text) {
#         const msg = new SpeechSynthesisUtterance(text);
#         msg.lang = 'en';
#         window.speechSynthesis.cancel();
#         window.speechSynthesis.speak(msg);
#     }
#     </script>
#     </body>
#     </html>
#     """
#
#     components.html(html, height=h+60, width=w+30)
#////////////////////////////////First//////////////////////////
# import streamlit as st
# from ultralytics import YOLO
# import cv2
# import numpy as np
# from PIL import Image
# import tempfile
#
# # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
# st.set_page_config(page_title="ğŸ” Image Detection with YOLOv8", page_icon="ğŸ“¸")
#
# st.title("ğŸ¯ YOLOv8 Image Detection App")
# st.markdown("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø©ØŒ ÙˆØ´ÙˆÙ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨Ø¹Ø¯ Ù…Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ­Ù„Ù„Ù‡Ø§ ğŸ‘ï¸â€ğŸ—¨ï¸")
#
# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
# @st.cache_resource
# def load_model():
#     return YOLO("yolov8n.pt")  # Ø£Ùˆ Ø­Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø§Ù„Ø®Ø§Øµ Ø¨ÙŠÙƒ Ù‡Ù†Ø§
#
# model = load_model()
#
# # Ø±ÙØ¹ ØµÙˆØ±Ø©
# uploaded_file = st.file_uploader("ğŸ“¤ Ø§Ø±ÙØ¹ ØµÙˆØ±Ø©", type=["jpg", "png", "jpeg"])
#
# if uploaded_file is not None:
#     # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
#     image = Image.open(uploaded_file).convert("RGB")
#     st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
#
#     # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ NumPy Array
#     img_array = np.array(image)
#
#     # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
#     with st.spinner("ğŸ¤– Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©..."):
#         results = model.predict(source=img_array, conf=0.4)
#         result_img = results[0].plot()
#
#         # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
#         st.image(result_img, caption="âœ… Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ù€ Detection", use_container_width=True)
